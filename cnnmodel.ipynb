{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnnmodel.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KxxHyoRim/WhatDoILookLike_CNN/blob/main/cnnmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfOF15EDZEHe"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "!ls\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('./MyDrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhW79391aUpw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.load_model(\"/content/MyDrive/MyDrive/cnn model/model/8(3,3,300)-loss: 0.6023 - accuracy: 0.8080 - val_loss: 0.8441 - val_accuracy: 0.7339.h5\", compile=False)\n",
        "\n",
        "export_path = '/content/MyDrive/MyDrive/cnn model/converted_pb.pb'\n",
        "model.save(export_path, save_format='tf')\n",
        "\n",
        "export_dir = '/content/MyDrive/MyDrive/cnn model/converted_pb.pb'\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()\n",
        "open('/content/MyDrive/MyDrive/cnn model/model/converted_model31.tflite', 'wb').write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACExL0ZpbET1"
      },
      "source": [
        "!ls\n",
        "import numpy\n",
        "import cv2, os\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfZV2auKhiOI"
      },
      "source": [
        "from tensorflow.python.keras.models import load_model\n",
        "\n",
        "model2 = load_model(\"/content/MyDrive/MyDrive/cnn model/model/8(3,3,300)-loss: 0.6023 - accuracy: 0.8080 - val_loss: 0.8441 - val_accuracy: 0.7339.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47lfDiUZhuYG"
      },
      "source": [
        "test = [] # test input\n",
        "cat2 = cv2.imread(\"/content/MyDrive/MyDrive/cnn model/train2/quokka/jungeun_output/training/images (15).jfif\")\n",
        "cat2 = cv2.cvtColor(cat2, cv2.COLOR_BGR2GRAY)\n",
        "cat2 = cv2.resize(cat2, (96, 96))\n",
        "cat2 = numpy.asarray(cat2) / 255\n",
        "cat2 = numpy.array(cat2)\n",
        "test.append(cat2)\n",
        "test = numpy.array(test)\n",
        "test = test.reshape((1, 96, 96, 1))\n",
        "y_test2 = model2.predict_classes(test)\n",
        "print(y_test2)\n",
        "# human = [\"희철\", \"예슬\", \"소희\", \"민현\", \"백현\", \"보영\", \"지민\", \"중기\", \"지훈\", \"정국\", \"나연\", \"수지\", \"경리\",\n",
        "#         \"제니\", \"주지훈\", \"준기\", \"엠버\", \"공유\", \"우희\", \"우빈\", \"미란\", \"진웅\", \"재홍\", \"슬기\", \"주연\",\n",
        "#         \"상이\",\"시원\", \"문세\", \"진우\", \"정은\", \"현희\", \"진\"]\n",
        "#print(human[y_test2[0]])\n",
        "#print(y_test2[0]//2)\n",
        "#print(animal[y_test2[0]//2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgJ3WIeBt1tW"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "animal = [\"cat\", \"dog\", \"rabbit\", \"fox\", \"dinosaur\", \"bear\", \"horse\", \"quokka\"]\n",
        "idx = 0\n",
        "human_index = 0\n",
        "human = []\n",
        "file_location = '/content/MyDrive/MyDrive/cnn model/train/'\n",
        "for p in animal:\n",
        "\n",
        "    print(\"> \" + animal[idx] + \" on Process\")\n",
        "    folder = file_location + animal[idx]\n",
        "\n",
        "    for i in os.listdir(folder):\n",
        "        folder_train = folder + \"/\" + i + \"/training\"\n",
        "        folder_test = folder + \"/\" + i + \"/validate\"\n",
        "        print(i[:-7])\n",
        "        human.append(i[:-7])\n",
        "        count = 0\n",
        "        # print(folder_train)\n",
        "        for j in os.listdir(folder_train):\n",
        "            if os.path.isfile(folder_train + \"/\" + j):\n",
        "                try :    # 파일이름이 한글이면 error -> 영어로 rename\n",
        "                    new_name = folder_train + \"/\" + 'trainImage' + str(count) + '.jfif'\n",
        "                    #os.rename(folder_train + \"/\" + j, new_name)\n",
        "                except:\n",
        "                    pass\n",
        "                # print(new_name)\n",
        "                img = cv2.imread(new_name)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                #img = cv2.resize(img, (50, 50))\n",
        "                img = numpy.asarray(img) / 255\n",
        "                x_train.append(img)\n",
        "                y_train.append(human_index)\n",
        "                count = count + 1\n",
        "            # if count == 87:  # 200\n",
        "                # break\n",
        "        # print(\"train image complete\")\n",
        "        count = 0\n",
        "        # print(folder_test)\n",
        "        for j in os.listdir(folder_test):\n",
        "            if os.path.isfile(folder_test + \"/\" + j):\n",
        "                try:  # 파일이름이 한글이면 error -> 영어로 rename\n",
        "                    new_name = folder_test + \"/\" + 'testImage' + str(count) + '.jfif'\n",
        "                    #os.rename(folder_test + \"/\" + j, new_name)\n",
        "                except:\n",
        "                    pass\n",
        "                # print(new_name)\n",
        "                img = cv2.imread(new_name)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                # img = cv2.resize(img, (50, 50))\n",
        "                img = numpy.asarray(img) / 255\n",
        "                x_test.append(img)\n",
        "                y_test.append(human_index)\n",
        "                count = count + 1\n",
        "        human_index = human_index + 1\n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXCSfeUyyZOk"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "animal = [\"cat\", \"dog\", \"rabbit\", \"fox\", \"dinosaur\", \"bear\", \"horse\", \"quokka\"]\n",
        "idx = 0\n",
        "human_index = 0\n",
        "human = []\n",
        "file_location = '/content/MyDrive/MyDrive/cnn model/train2/'\n",
        "for p in animal:\n",
        "\n",
        "    print(\"> \" + animal[idx] + \" on Process\")\n",
        "    folder = file_location + animal[idx]\n",
        "\n",
        "    for i in os.listdir(folder):\n",
        "        folder_train = folder + \"/\" + i + \"/training\"\n",
        "        folder_test = folder + \"/\" + i + \"/validate\"\n",
        "        print(i[:-7])\n",
        "        human.append(i[:-7])\n",
        "        count = 0\n",
        "        # print(folder_train)\n",
        "        train_count=0\n",
        "        test_count=0\n",
        "        for j in os.listdir(folder_train):\n",
        "            if os.path.isfile(folder_train + \"/\" + j):\n",
        "                try :    # 파일이름이 한글이면 error -> 영어로 rename\n",
        "                    new_name = folder_train + \"/\" + 'trainImage' + str(count) + '.jfif'\n",
        "                    #os.rename(folder_train + \"/\" + j, new_name)\n",
        "                except:\n",
        "                    pass\n",
        "                # print(new_name)\n",
        "                train_count = train_count + 1\n",
        "                img = cv2.imread(folder_train + \"/\" + j)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                img = cv2.resize(img, (50, 50))\n",
        "                img = numpy.asarray(img) / 255\n",
        "                x_train.append(img)\n",
        "                y_train.append(human_index)\n",
        "                count = count + 1\n",
        "            # if count == 87:  # 200\n",
        "                # break\n",
        "        # print(\"train image complete\")\n",
        "        count = 0\n",
        "        # print(folder_test)\n",
        "        for j in os.listdir(folder_test):\n",
        "            if os.path.isfile(folder_test + \"/\" + j):\n",
        "                try:  # 파일이름이 한글이면 error -> 영어로 rename\n",
        "                    new_name = folder_test + \"/\" + 'testImage' + str(count) + '.jfif'\n",
        "                    #os.rename(folder_test + \"/\" + j, new_name)\n",
        "                except:\n",
        "                    pass\n",
        "                # print(new_name)\n",
        "                test_count = test_count + 1\n",
        "                img = cv2.imread(folder_test + \"/\" + j)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                img = cv2.resize(img, (50, 50))\n",
        "                img = numpy.asarray(img) / 255\n",
        "                x_test.append(img)\n",
        "                y_test.append(human_index)\n",
        "                count = count + 1\n",
        "        human_index = human_index + 1\n",
        "        print(str(train_count) + \",  \" + str(test_count))\n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpN7IBO8ysHV"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "animal = [\"cat\", \"dog\", \"rabbit\", \"fox\", \"dinosaur\", \"bear\", \"horse\", \"quokka\"]\n",
        "idx = 0\n",
        "human_index = 0\n",
        "human = []\n",
        "file_location = '/content/MyDrive/MyDrive/cnn model/train2/'\n",
        "for p in animal:\n",
        "\n",
        "    print(\"> \" + animal[idx] + \" on Process\")\n",
        "    folder = file_location + animal[idx]\n",
        "\n",
        "    for i in os.listdir(folder):\n",
        "        folder_train = folder + \"/\" + i + \"/training\"\n",
        "        folder_test = folder + \"/\" + i + \"/validate\"\n",
        "        print(i[:-7])\n",
        "        human.append(i[:-7])\n",
        "        count = 0\n",
        "        # print(folder_train)\n",
        "        train_count=0\n",
        "        test_count=0\n",
        "        for j in os.listdir(folder_train):\n",
        "            if os.path.isfile(folder_train + \"/\" + j):\n",
        "                try :    # 파일이름이 한글이면 error -> 영어로 rename\n",
        "                    new_name = folder_train + \"/\" + 'trainImage' + str(count) + '.jfif'\n",
        "                    #os.rename(folder_train + \"/\" + j, new_name)\n",
        "                except:\n",
        "                    pass\n",
        "                # print(new_name)\n",
        "                train_count = train_count + 1\n",
        "                img = cv2.imread(new_name)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                #img = cv2.resize(img, (50, 50))\n",
        "                img = numpy.asarray(img) / 255\n",
        "                x_train.append(img)\n",
        "                y_train.append(idx)\n",
        "                count = count + 1\n",
        "            # if count == 87:  # 200\n",
        "                # break\n",
        "        # print(\"train image complete\")\n",
        "        count = 0\n",
        "        # print(folder_test)\n",
        "        for j in os.listdir(folder_test):\n",
        "            if os.path.isfile(folder_test + \"/\" + j):\n",
        "                try:  # 파일이름이 한글이면 error -> 영어로 rename\n",
        "                    new_name = folder_test + \"/\" + 'testImage' + str(count) + '.jfif'\n",
        "                    os.rename(folder_test + \"/\" + j, new_name)\n",
        "                except:\n",
        "                    pass\n",
        "                test_count = test_count + 1\n",
        "                # print(new_name)\n",
        "                img = cv2.imread(new_name)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                # img = cv2.resize(img, (50, 50))\n",
        "                img = numpy.asarray(img) / 255\n",
        "                x_test.append(img)\n",
        "                y_test.append(idx)\n",
        "                count = count + 1\n",
        "        human_index = human_index + 1\n",
        "        print(str(train_count) + \",  \" + str(test_count))\n",
        "    idx += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mazcE9Y_5yVS"
      },
      "source": [
        "x_train = numpy.array(x_train)\n",
        "x_train = x_train.reshape(x_train.shape[0], 96, 96, 1)\n",
        "\n",
        "x_test = numpy.array(x_test)\n",
        "x_test = x_test.reshape(x_test.shape[0], 96, 96, 1)\n",
        "\n",
        "y_train = numpy.asarray(y_train)\n",
        "y_train = y_train.reshape(y_train.shape[0], 1)\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "\n",
        "y_test = numpy.asarray(y_test)\n",
        "y_test = y_test.reshape(y_test.shape[0], 1)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YwtkBOv6IFo"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(human)\n",
        "print(y_train[163])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEn9LUfr6YGx"
      },
      "source": [
        "#1\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(8, 8), input_shape=(50, 50, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200, batch_size=50, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMBiFHLnVuXa"
      },
      "source": [
        "#2\n",
        "model = Sequential()\n",
        "model.add(Conv2D(96, kernel_size=(8, 8), input_shape=(50, 50, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200, batch_size=50, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPkBFBBWYKQy"
      },
      "source": [
        "#3\n",
        "model = Sequential()\n",
        "model.add(Conv2D(96, kernel_size=(8, 8), input_shape=(50, 50, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200, batch_size=50, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr_7YHJ4cCTz"
      },
      "source": [
        "#4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(96, kernel_size=(8, 8), input_shape=(50, 50, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200, batch_size=50, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLPir0mpLwy8"
      },
      "source": [
        "#5\n",
        "model = Sequential()\n",
        "model.add(Conv2D(96, kernel_size=(8, 8), input_shape=(96, 96, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200, batch_size=50, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDxl2DzsL56i"
      },
      "source": [
        "#6\n",
        "model = Sequential()\n",
        "model.add(Conv2D(96, kernel_size=(8, 8), input_shape=(96, 96, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200, batch_size=50, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uTrXntbOaUg"
      },
      "source": [
        "#7\n",
        "model = Sequential()\n",
        "model.add(Conv2D(96, kernel_size=(10, 10), input_shape=(96, 96, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200, batch_size=50, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRHQIuf5E4Gv"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(96, kernel_size=(3, 3), input_shape=(96, 96, 1), \n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=500, batch_size=300, verbose=1, callbacks=[early_stopping_callback, checkpointer])\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFHg5CZn8xZb"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label = 'train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label = 'val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label = 'train accuracy')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label = 'valid accuracy')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhHjYp2puY94"
      },
      "source": [
        "#9\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), input_shape=(224, 224, 1), activation='relu'))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2048, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(521, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=15)\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=500, batch_size=250, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxkV0mFe_NFb"
      },
      "source": [
        "test = [] # test input\n",
        "cat2 = cv2.imread(\"/content/MyDrive/MyDrive/cnn model/test/jin.PNG\")\n",
        "cat2 = cv2.cvtColor(cat2, cv2.COLOR_BGR2GRAY)\n",
        "cat2 = cv2.resize(cat2, (96, 96))\n",
        "cat2 = numpy.asarray(cat2) / 255\n",
        "cat2 = numpy.array(cat2)\n",
        "test.append(cat2)\n",
        "test = numpy.array(test)\n",
        "test = test.reshape((1, 96, 96, 1))\n",
        "y_test2 = model.predict_classes(test)\n",
        "print(y_test2)\n",
        "# human = [\"희철\", \"예슬\", \"소희\", \"민현\", \"백현\", \"보영\", \"지민\", \"중기\", \"지훈\", \"정국\", \"나연\", \"수지\", \"경리\",\n",
        "#         \"제니\", \"주지훈\", \"준기\", \"엠버\", \"공유\", \"우희\", \"우빈\", \"미란\", \"진웅\", \"재홍\", \"슬기\", \"주연\",\n",
        "#         \"상이\",\"시원\", \"문세\", \"진우\", \"정은\", \"현희\", \"진\"]\n",
        "print(human[y_test2[0]])\n",
        "#print(y_test2[0]//2)\n",
        "print(animal[y_test2[0]//2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bftz1I0w_ick"
      },
      "source": [
        "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.python.keras.models import Model\n",
        "\n",
        "# 사전 학습된 모델 불러오기\n",
        "input_tensor = Input(shape=(96,96,3))\n",
        "model = VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "\n",
        "# Layer 추가\n",
        "x = layer_dict['block5_pool'].output\n",
        "# Cov2D Layer +\n",
        "x = Conv2D(filters = 64, kernel_size=(3, 3), activation='relu')(x)\n",
        "# MaxPooling2D Layer +\n",
        "#x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "# Flatten Layer +\n",
        "x = Flatten()(x)\n",
        "# FC Layer +\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(16, activation='softmax')(x)\n",
        "\n",
        "# new model 정의\n",
        "new_model = Model(inputs = model.input, outputs = x)\n",
        "\n",
        "# CNN Pre-trained 가중치를 그대로 사용할때\n",
        "for layer in new_model.layers[:19] :\n",
        "    layer.trainable = False\n",
        "\n",
        "new_model.summary()\n",
        "new_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "MODEL_DIR = '/content/MyDrive/MyDrive/cnn model/model/'\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    os.mkdir(MODEL_DIR)\n",
        "\n",
        "modelpath = \"/content/MyDrive/MyDrive/cnn model/model/{epoch:02d}-{val_loss:.4f}.h5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=15)\n",
        "\n",
        "#model.fit(x_train, validation_data=(x_test, y_test), epochs=500, batch_size=250, verbose=1, callbacks=[early_stopping_callback, checkpointer])\n",
        " \n",
        "history = new_model.fit(x_test, epochs=5, validation_data=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}